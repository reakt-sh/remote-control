{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74de731",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba29f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e608f",
   "metadata": {},
   "source": [
    "### Setup plotting style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a compatible matplotlib style and seaborn settings\n",
    "plt.style.use('default')  # Use default matplotlib style\n",
    "sns.set_theme(style=\"darkgrid\")  # Modern seaborn theme setting\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Additional styling for better plots\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72942f3",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d611962",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Test Case 1:\n",
    "          - Train client is a Laptop connected to 5G network\n",
    "          - Web client is a Laptop connected to 5G network\n",
    "'''\n",
    "#filename =  './29_08_2025/pre_processed/processed_Train_Client(Laptop)_Web_Client(Laptop)_e1c07b43-9e1e-4438-ade8-a320a030e494_Latency.json'\n",
    "\n",
    "\n",
    "'''\n",
    "    Test Case 2:\n",
    "          - Train client is a Laptop connected to 5G network\n",
    "          - Web client is a Phone connected to 5G network\n",
    "'''\n",
    "# filename =  './29_08_2025/pre_processed/processed_Train_Client(Laptop)_Web_Client(Mobile_DE)_5d6a5a85-6566-45b9-8b57-48e886539e0b_Latency.json'\n",
    "\n",
    "\n",
    "'''\n",
    "    Test Case 3:\n",
    "          - Train client is a Laptop connected to 5G network (Germany)\n",
    "          - Web client is a Phone connected to 4G network (Bangladesh)\n",
    "'''\n",
    "# filename =  './29_08_2025/pre_processed/processed_Train_Client(Laptop)_Web_Client(Mobile_BD)_1bdb4d47-a2e0-4148-a721-796cf6ff755b_Latency.json'\n",
    "\n",
    "'''\n",
    "    Test Case 4:\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Laptop connected to Wifi network\n",
    "'''\n",
    "# filename =  './11_12_2025/train_e127f95e-e9a0-46d4-9ac0-6b9783533ec2_latency_1765452450000_1765452650000.json'\n",
    "\n",
    "'''\n",
    "    Test Case 5:\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Laptop connected to Wifi network\n",
    "          - date: 18th December 2025\n",
    "'''\n",
    "# filename =  './2025_12_18/train_72275261-bd04-436f-bc49-39af129914e9_latency_1766056830000_1766057039000.json'\n",
    "\n",
    "'''\n",
    "    Test Case 6:\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Laptop connected to Wifi network\n",
    "          - date: 15th January 2026\n",
    "'''\n",
    "# filename =  './2026_01_16/train_14c82344-01dc-41da-af98-95a5ea67f115_latency_1768569238000_1768569346000.json'\n",
    "\n",
    "'''\n",
    "    Test Case 7:\n",
    "          - Scenario 01\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 21th January 2026\n",
    "'''\n",
    "# filename = './2026_01_21/20260116_171827_Scene_01/latency_video_20260116_171828.json'\n",
    "\n",
    "'''\n",
    "    Test Case 8:\n",
    "          - Scenario 02\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 21th January 2026\n",
    "'''\n",
    "# filename = './2026_01_21/20260116_172945_Scene_02/latency_video_20260116_172945.json'\n",
    "\n",
    "\n",
    "'''\n",
    "    Test Case 9:\n",
    "          - Scenario 01\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 5th February 2026\n",
    "          - setup: 1280x720 resolution, 30FPS, 2Mbps bitrate\n",
    "'''\n",
    "# filename = './2026_02_05/20260117_040403_1280x720_30FPS_2Mbps/train_6654876e-178e-4f8c-b6d6-bf0046eb6562_latency_Remote_Control.json'\n",
    "# file_command_latency = './2026_02_05/20260117_040403_1280x720_30FPS_2Mbps/latency_20260117_040403.json'\n",
    "# hardware_usage = './2026_02_05/20260117_040403_1280x720_30FPS_2Mbps/hw_usage_20260117_040403.json'\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    Test Case 10:\n",
    "          - Scenario 01\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 5th February 2026\n",
    "          - setup: 1280x720 resolution, 30FPS, 5Mbps bitrate\n",
    "'''\n",
    "# hardware_usage = './2026_02_05/20260117_042655_1280x720_30FPS_5Mbps/hw_usage_20260117_042655.json'\n",
    "# file_command_latency = './2026_02_05/20260117_042655_1280x720_30FPS_5Mbps/latency_20260117_042655.json'\n",
    "# filename = './2026_02_05/20260117_042655_1280x720_30FPS_5Mbps/train_d97eff25-1854-4d5b-abc9-f5d86613328f_latency_Remote_Control.json'\n",
    "\n",
    "'''\n",
    "    Test Case 11:\n",
    "          - Scenario 01\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 5th February 2026\n",
    "          - setup: 640x480 resolution, 30FPS, 2Mbps bitrate\n",
    "'''\n",
    "\n",
    "# hardware_usage = './2026_02_05/20260117_044328_640x480_30FPS_2Mbps/hw_usage_20260117_044328.json'\n",
    "# file_command_latency = './2026_02_05/20260117_044328_640x480_30FPS_2Mbps/latency_20260117_044328.json'\n",
    "# filename = './2026_02_05/20260117_044328_640x480_30FPS_2Mbps/train_19ff9f51-763d-4c9b-b636-b26f9a50b069_latency_Remote_Control.json'\n",
    "\n",
    "'''\n",
    "    Test Case 12:\n",
    "          - Scenario 01\n",
    "          - Train client is reakt-Tiny connected to Wifi network\n",
    "          - Web client is a Samsung S23 Ultra connected to Wifi network\n",
    "          - date: 5th February 2026\n",
    "          - setup: 640x480 resolution, 60FPS, 2Mbps bitrate\n",
    "'''\n",
    "\n",
    "hardware_usage = './2026_02_05/20260117_045857_640x480_60FPS_2Mbps/hw_usage_20260117_045858.json'\n",
    "file_command_latency = './2026_02_05/20260117_045857_640x480_60FPS_2Mbps/latency_20260117_045858.json'\n",
    "filename = './2026_02_05/20260117_045857_640x480_60FPS_2Mbps/train_94295ccb-00a6-4e10-9a78-b7df01a8168b_latency_Remote_Control.json'\n",
    "\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(f\"Data loaded successfully from {filename}\")\n",
    "print(f\"Data type: {type(data)}\")\n",
    "print(f\"Data keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dictionary'}\")\n",
    "\n",
    "# Convert to DataFrames for easier analysis\n",
    "telemetry_df = pd.DataFrame(data['telemetryLatencies'])\n",
    "video_df = pd.DataFrame(data['videoLatencies'])\n",
    "\n",
    "# export video_df to excel file\n",
    "video_df.to_excel('video_latencies.xlsx', index=False)\n",
    "\n",
    "# Create a summary DataFrame from statistics\n",
    "protocols = ['websocket', 'webtransport', 'mqtt']\n",
    "stats_data = []\n",
    "for protocol in protocols:\n",
    "    stats_data.append({\n",
    "        'protocol': protocol,\n",
    "        'count': data['statistics'][protocol]['count'],\n",
    "        'avg': data['statistics'][protocol]['avg'],\n",
    "        'min': data['statistics'][protocol]['min'],\n",
    "        'max': data['statistics'][protocol]['max']\n",
    "    })\n",
    "stats_df = pd.DataFrame(stats_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59011050",
   "metadata": {},
   "source": [
    "#### 1.1 Basic Statistics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f481b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Protocol Statistics Comparison:\")\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736a95f",
   "metadata": {},
   "source": [
    "#### 1.2 Visualization of protocol performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82250b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(25, 8))  # Increased figure height\n",
    "\n",
    "# Average latency by protocol with data count labels\n",
    "bars_avg = axes[0].bar(stats_df['protocol'], stats_df['avg'])\n",
    "axes[0].set_title('Average Latency by Protocol', fontsize=12, fontweight='bold', pad=20)\n",
    "axes[0].set_ylabel('Latency (ms)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add count labels on top of average latency bars\n",
    "for i, (bar, row) in enumerate(zip(bars_avg, stats_df.itertuples())):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{row.avg:.1f}ms\\n({row.count} samples)',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Min-Max latency range\n",
    "for i, row in stats_df.iterrows():\n",
    "    axes[1].plot([row['protocol'], row['protocol']], [row['min'], row['max']],\n",
    "                   marker='o', linewidth=3, markersize=8)\n",
    "\n",
    "    # Add labels for min and max values\n",
    "    # Label for maximum value (top)\n",
    "    axes[1].text(i, row['max'] + (row['max'] - row['min']) * 0.05,\n",
    "                f'Max: {row[\"max\"]:.1f}ms',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "    # Label for minimum value (bottom)\n",
    "    axes[1].text(i, row['min'] - (row['max'] - row['min']) * 0.05,\n",
    "                f'Min: {row[\"min\"]:.1f}ms',\n",
    "                ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightcoral', alpha=0.7))\n",
    "\n",
    "axes[1].set_title('Latency Range (Min-Max) by Protocol', fontsize=12, fontweight='bold', pad=20)\n",
    "axes[1].set_ylabel('Latency (ms)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Check for missing values in telemetry data\n",
    "print(\"Missing values in telemetry data:\")\n",
    "print(f\"MQTT: {telemetry_df['mqtt'].isna().sum()}\")\n",
    "print(f\"WebTransport: {telemetry_df['wt'].isna().sum()}\")\n",
    "print(f\"WebSocket: {telemetry_df['ws'].isna().sum()}\")\n",
    "\n",
    "# Calculate missing percentages\n",
    "total_records = len(telemetry_df)\n",
    "missing_percentages = {\n",
    "    'MQTT': (telemetry_df['mqtt'].isna().sum() / total_records) * 100,\n",
    "    'WebTransport': (telemetry_df['wt'].isna().sum() / total_records) * 100,\n",
    "    'WebSocket': (telemetry_df['ws'].isna().sum() / total_records) * 100\n",
    "}\n",
    "\n",
    "# Missing percentage by protocol\n",
    "protocols_missing = list(missing_percentages.keys())\n",
    "percentages = list(missing_percentages.values())\n",
    "\n",
    "bars = axes[2].bar(protocols_missing, percentages)\n",
    "axes[2].set_title('Missing Data Percentage by Protocol', fontsize=12, fontweight='bold', pad=20)\n",
    "axes[2].set_ylabel('Missing Percentage (%)')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for bar, percentage in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{percentage:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Set y-axis limit for better visualization\n",
    "axes[2].set_ylim(0, max(percentages) * 1.2 if max(percentages) > 0 else 10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  # Add extra space at the top for the titles\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMissing data percentages:\")\n",
    "for protocol, percentage in missing_percentages.items():\n",
    "    print(f\"{protocol}: {percentage:.2f}%\")\n",
    "\n",
    "# Print telemetry data count summary\n",
    "print(f\"\\nTelemetry data processed by each protocol:\")\n",
    "for _, row in stats_df.iterrows():\n",
    "    print(f\"{row['protocol']}: {row['count']} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56842c4b",
   "metadata": {},
   "source": [
    "#### 2.1 Time Series analysis of telemetry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data shape and info\n",
    "print(f\"\\nTelemetry data shape: {telemetry_df.shape}\")\n",
    "print(f\"Sequence ID range: {telemetry_df['sequence_id'].min()} - {telemetry_df['sequence_id'].max()}\")\n",
    "\n",
    "# Display first few rows to understand the data structure\n",
    "print(\"\\nFirst 10 rows of telemetry data:\")\n",
    "print(telemetry_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3454fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Original data with gaps vs Interpolated data\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(20, 8))\n",
    "\n",
    "# Original data (with potential gaps)\n",
    "ax1.plot(telemetry_df['sequence_id'], telemetry_df['mqtt'], marker='o', label='MQTT', linewidth=2, markersize=4, alpha=0.7)\n",
    "ax1.plot(telemetry_df['sequence_id'], telemetry_df['wt'], marker='s', label='WebTransport', linewidth=2, markersize=4, alpha=0.7)\n",
    "ax1.plot(telemetry_df['sequence_id'], telemetry_df['ws'], marker='^', label='WebSocket', linewidth=2, markersize=4, alpha=0.7)\n",
    "ax1.set_xlabel('Sequence ID')\n",
    "ax1.set_ylabel('Latency (ms)')\n",
    "ax1.set_title('Original Telemetry Data (with potential gaps)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Add extra space at the top for the title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87786e6",
   "metadata": {},
   "source": [
    "#### 2.2 Cumulative Latency Analysis for telemetry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f49bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cumulative latency data with interpolation for null values\n",
    "telemetry_clean_cumulative = telemetry_df.copy()\n",
    "\n",
    "# First, interpolate null values for each protocol\n",
    "print(\"Before interpolation:\")\n",
    "print(f\"MQTT null values: {telemetry_clean_cumulative['mqtt'].isna().sum()}\")\n",
    "print(f\"WebTransport null values: {telemetry_clean_cumulative['wt'].isna().sum()}\")\n",
    "print(f\"WebSocket null values: {telemetry_clean_cumulative['ws'].isna().sum()}\")\n",
    "\n",
    "# Interpolate missing values using linear interpolation\n",
    "telemetry_clean_cumulative['mqtt'] = telemetry_clean_cumulative['mqtt'].interpolate(method='linear')\n",
    "telemetry_clean_cumulative['wt'] = telemetry_clean_cumulative['wt'].interpolate(method='linear')\n",
    "telemetry_clean_cumulative['ws'] = telemetry_clean_cumulative['ws'].interpolate(method='linear')\n",
    "\n",
    "print(\"\\nAfter interpolation:\")\n",
    "print(f\"MQTT null values: {telemetry_clean_cumulative['mqtt'].isna().sum()}\")\n",
    "print(f\"WebTransport null values: {telemetry_clean_cumulative['wt'].isna().sum()}\")\n",
    "print(f\"WebSocket null values: {telemetry_clean_cumulative['ws'].isna().sum()}\")\n",
    "\n",
    "# Calculate cumulative latencies for each protocol\n",
    "telemetry_clean_cumulative['mqtt_cumulative'] = telemetry_clean_cumulative['mqtt'].cumsum()\n",
    "telemetry_clean_cumulative['wt_cumulative'] = telemetry_clean_cumulative['wt'].cumsum()\n",
    "telemetry_clean_cumulative['ws_cumulative'] = telemetry_clean_cumulative['ws'].cumsum()\n",
    "\n",
    "print(\"\\nCumulative latency data created successfully!\")\n",
    "print(f\"Shape: {telemetry_clean_cumulative.shape}\")\n",
    "print(\"\\nFirst 10 rows of cumulative data:\")\n",
    "print(telemetry_clean_cumulative[['sequence_id', 'mqtt_cumulative', 'wt_cumulative', 'ws_cumulative']].head(10))\n",
    "print(\"\\nLast 10 rows of cumulative data:\")\n",
    "print(telemetry_clean_cumulative[['sequence_id', 'mqtt_cumulative', 'wt_cumulative', 'ws_cumulative']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative latencies\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(telemetry_clean_cumulative['sequence_id'], telemetry_clean_cumulative['mqtt_cumulative'],\n",
    "         marker='o', label='MQTT (Cumulative)', linewidth=3, markersize=4)\n",
    "plt.plot(telemetry_clean_cumulative['sequence_id'], telemetry_clean_cumulative['wt_cumulative'],\n",
    "         marker='s', label='WebTransport (Cumulative)', linewidth=3, markersize=4)\n",
    "plt.plot(telemetry_clean_cumulative['sequence_id'], telemetry_clean_cumulative['ws_cumulative'],\n",
    "         marker='^', label='WebSocket (Cumulative)', linewidth=3, markersize=4)\n",
    "\n",
    "plt.xlabel('Sequence ID', fontsize=12)\n",
    "plt.ylabel('Cumulative Latency (ms)', fontsize=12)\n",
    "plt.title('Cumulative Telemetry Latencies Over Time', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Add extra space at the top for the title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067730c",
   "metadata": {},
   "source": [
    "#### 3. Video Frame Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a07edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Time series analysis of video latencies\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Calculate averages\n",
    "avg_latency = video_df['latency'].mean()\n",
    "avg_data_size = video_df['data_size'].mean()\n",
    "\n",
    "# 1. Data size over frame sequence (top subplot)\n",
    "axes[0].bar(video_df['frameId'], video_df['data_size'], width=1.0, alpha=0.8, \n",
    "            color='orange', edgecolor='darkorange', linewidth=0.5, label='Frame Data Size')\n",
    "\n",
    "# Add horizontal line for average data size\n",
    "axes[0].axhline(y=avg_data_size, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Average Data Size: {avg_data_size:.2f} bytes')\n",
    "\n",
    "axes[0].set_xlabel('Frame ID', fontsize=14)\n",
    "axes[0].set_ylabel('Data Size (bytes)', fontsize=14)\n",
    "axes[0].set_ylim(0, 200000)  # Set y-axis static limit for better visualization\n",
    "axes[0].set_title('Video Frame Data Size Over Time', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Latency over frame sequence (bottom subplot)\n",
    "axes[1].bar(video_df['frameId'], video_df['latency'], width=1.0, alpha=0.8, \n",
    "            color='steelblue', edgecolor='navy', linewidth=0.5, label='Video Frame Latency')\n",
    "\n",
    "# Add horizontal line for average latency\n",
    "axes[1].axhline(y=avg_latency, color='purple', linestyle='--', linewidth=2,\n",
    "                label=f'Average Latency: {avg_latency:.2f} ms')\n",
    "\n",
    "axes[1].set_xlabel('Frame ID', fontsize=14)\n",
    "axes[1].set_ylabel('Latency (ms)', fontsize=14)\n",
    "axes[1].set_ylim(0, 300) # Set y-axis static limit for better visualization\n",
    "axes[1].set_title('Video Frame Latency Over Time', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Analysis of missing video frames\n",
    "if not video_df.empty:\n",
    "    # Find the first and last frame IDs\n",
    "    first_frame_id = video_df['frameId'].min()\n",
    "    last_frame_id = video_df['frameId'].max()\n",
    "\n",
    "    # Calculate the total number of expected frames\n",
    "    total_expected_frames = last_frame_id - first_frame_id + 1\n",
    "\n",
    "    # Calculate the number of received frames\n",
    "    received_frames_count = len(video_df)\n",
    "\n",
    "    # Calculate the number of missing frames\n",
    "    missing_frames_count = total_expected_frames - received_frames_count\n",
    "\n",
    "    print(f\"First received frame ID: {first_frame_id}\")\n",
    "    print(f\"Last received frame ID: {last_frame_id}\")\n",
    "    print(f\"Total expected frames in sequence: {total_expected_frames}\")\n",
    "    print(f\"Number of received frames: {received_frames_count}\")\n",
    "    print(f\"Number of missing frames: {missing_frames_count}\")\n",
    "    print(f\"Missing frame percentage: {(missing_frames_count/total_expected_frames)*100:.2f}%\")\n",
    "\n",
    "    # Identify the missing frame IDs\n",
    "    expected_frame_ids = set(range(first_frame_id, last_frame_id + 1))\n",
    "    received_frame_ids = set(video_df['frameId'])\n",
    "    missing_frame_ids = sorted(list(expected_frame_ids - received_frame_ids))\n",
    "\n",
    "    print(f\"\\nMissing frame IDs: {missing_frame_ids if missing_frames_count > 0 else 'None'}\")\n",
    "\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 12))  # Increased figure height\n",
    "\n",
    "    # 1. Overall view with improved markers\n",
    "    all_frames = pd.DataFrame({'frameId': list(range(first_frame_id, last_frame_id + 1))})\n",
    "    all_frames['status'] = 'Missing'\n",
    "    all_frames.loc[all_frames['frameId'].isin(received_frame_ids), 'status'] = 'Received'\n",
    "\n",
    "    # Plot with larger, more visible markers\n",
    "    received_data = all_frames[all_frames['status'] == 'Received']\n",
    "    missing_data = all_frames[all_frames['status'] == 'Missing']\n",
    "\n",
    "    axes[0].scatter(received_data['frameId'], [1]*len(received_data), \n",
    "                   c='green', alpha=0.6, s=50, marker='o', label=f'Received ({len(received_data)})')\n",
    "    axes[0].scatter(missing_data['frameId'], [1]*len(missing_data), \n",
    "                   c='red', s=50, marker='x', label=f'Missing ({len(missing_data)})', linewidths=2)\n",
    "\n",
    "    axes[0].set_title('Visualization of Received and Missing Video Frames (Overall View)', \n",
    "                     fontsize=14, fontweight='bold', pad=25)  # Increased padding\n",
    "    axes[0].set_xlabel('Frame ID', fontsize=16)\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_ylabel('')\n",
    "    axes[0].legend(title='Frame Status', fontsize=14)\n",
    "    axes[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axes[0].grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # 2. Missing frames density visualization\n",
    "    if missing_frame_ids:\n",
    "        # Create bins to show missing frame density\n",
    "        bin_size = 200  # frames per bin\n",
    "        bins = range(first_frame_id, last_frame_id + bin_size, bin_size)\n",
    "        missing_counts, bin_edges = np.histogram(missing_frame_ids, bins=bins)\n",
    "        bin_centers = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_edges)-1)]\n",
    "\n",
    "        axes[1].bar(bin_centers, missing_counts, width=bin_size*0.8, alpha=0.7, color='red', edgecolor='darkred')\n",
    "        axes[1].set_title(f'Missing Frame Density (Bin Size: {bin_size} frames)', \n",
    "                         fontsize=14, fontweight='bold', pad=25)  # Increased padding\n",
    "        axes[1].set_xlabel('Frame ID Range', fontsize=16)\n",
    "        axes[1].set_ylabel('Number of Missing Frames', fontsize=16)\n",
    "        axes[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92, hspace=0.3)  # Add extra space at top and between subplots\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    if missing_frame_ids:\n",
    "        print(f\"\\nMissing Frame Analysis:\")\n",
    "        print(f\"- First missing frame: {min(missing_frame_ids)}\")\n",
    "        print(f\"- Last missing frame: {max(missing_frame_ids)}\")\n",
    "        print(f\"- Average gap between consecutive missing frames: {np.mean(np.diff(missing_frame_ids)):.1f}\")\n",
    "        if len(missing_frame_ids) > 1:\n",
    "            print(f\"- Largest gap between consecutive missing frames: {max(np.diff(missing_frame_ids))}\")\n",
    "\n",
    "else:\n",
    "    print(\"Video data is empty. Cannot perform missing frame analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Box plot  analysis of video latencies\n",
    "# Create box plot for video frame latencies\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Create box plot\n",
    "box_plot = plt.boxplot([video_df['latency'].values],\n",
    "                        labels=['Video Frame Latency'],\n",
    "                        patch_artist=True,\n",
    "                        showmeans=False,\n",
    "                        medianprops=dict(color='black', linewidth=2),\n",
    "                        boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                        whiskerprops=dict(linewidth=1.5),\n",
    "                        capprops=dict(linewidth=1.5))\n",
    "\n",
    "plt.ylabel('Latency (ms)', fontsize=14, fontweight='bold')\n",
    "plt.title('Video Frame Latency Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 300)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add statistics annotations\n",
    "stats_text = f\"n = {len(video_df)}\\n\"\n",
    "stats_text += f\"Mean = {video_df['latency'].mean():.2f} ms\\n\"\n",
    "stats_text += f\"Median = {video_df['latency'].median():.2f} ms\\n\"\n",
    "stats_text += f\"Std Dev = {video_df['latency'].std():.2f} ms\\n\"\n",
    "stats_text += f\"Min = {video_df['latency'].min():.2f} ms\\n\"\n",
    "stats_text += f\"Max = {video_df['latency'].max():.2f} ms\\n\"\n",
    "stats_text += f\"Q1 = {video_df['latency'].quantile(0.25):.2f} ms\\n\"\n",
    "stats_text += f\"Q3 = {video_df['latency'].quantile(0.75):.2f} ms\\n\"\n",
    "stats_text += f\"IQR = {video_df['latency'].quantile(0.75) - video_df['latency'].quantile(0.25):.2f} ms\"\n",
    "\n",
    "# Add text box with statistics\n",
    "plt.text(1.25, video_df['latency'].median(), stats_text,\n",
    "         fontsize=11, verticalalignment='center',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"Video Frame Latency Statistics:\")\n",
    "print(f\"  Total frames: {len(video_df)}\")\n",
    "print(f\"  Mean: {video_df['latency'].mean():.2f} ms\")\n",
    "print(f\"  Median: {video_df['latency'].median():.2f} ms\")\n",
    "print(f\"  Std Dev: {video_df['latency'].std():.2f} ms\")\n",
    "print(f\"  Min: {video_df['latency'].min():.2f} ms\")\n",
    "print(f\"  Max: {video_df['latency'].max():.2f} ms\")\n",
    "print(f\"  Q1 (25%): {video_df['latency'].quantile(0.25):.2f} ms\")\n",
    "print(f\"  Q3 (75%): {video_df['latency'].quantile(0.75):.2f} ms\")\n",
    "print(f\"  IQR: {video_df['latency'].quantile(0.75) - video_df['latency'].quantile(0.25):.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Analysis of bandwidth usage in each seconds for video transmission\n",
    "# video_df has a 'data_size' column in bytes and a 'stored_at' column in timestamp format\n",
    "\n",
    "# Convert stored_at timestamp to datetime\n",
    "video_df['timestamp'] = pd.to_datetime(video_df['stored_at'], unit='ms')\n",
    "\n",
    "# Extract second-level timestamp (remove microseconds for grouping)\n",
    "video_df['second'] = video_df['timestamp'].dt.floor('S')\n",
    "\n",
    "# Group by second and calculate total data size (in bytes) per second\n",
    "bandwidth_per_second = video_df.groupby('second').agg({\n",
    "    'data_size': 'sum',\n",
    "    'frameId': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "bandwidth_per_second.columns = ['second', 'total_bytes', 'frame_count']\n",
    "\n",
    "# Convert bytes to kilobits per second (Kbps)\n",
    "bandwidth_per_second['bandwidth_kbps'] = (bandwidth_per_second['total_bytes'] * 8) / 1000\n",
    "\n",
    "# Convert bytes to megabits per second (Mbps)\n",
    "bandwidth_per_second['bandwidth_mbps'] = (bandwidth_per_second['total_bytes'] * 8) / (1000 * 1000)\n",
    "\n",
    "# Create a time index relative to the start (in seconds)\n",
    "bandwidth_per_second['time_offset'] = (bandwidth_per_second['second'] - bandwidth_per_second['second'].min()).dt.total_seconds()\n",
    "\n",
    "# Display statistics\n",
    "print(\"Bandwidth Usage Statistics:\")\n",
    "print(f\"Total frames analyzed: {len(video_df)}\")\n",
    "print(f\"Total data transmitted: {video_df['data_size'].sum() / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Duration: {bandwidth_per_second['time_offset'].max():.0f} seconds\")\n",
    "print(f\"\\nBandwidth per second (Mbps):\")\n",
    "print(f\"  Mean: {bandwidth_per_second['bandwidth_mbps'].mean():.2f} Mbps\")\n",
    "print(f\"  Median: {bandwidth_per_second['bandwidth_mbps'].median():.2f} Mbps\")\n",
    "print(f\"  Min: {bandwidth_per_second['bandwidth_mbps'].min():.2f} Mbps\")\n",
    "print(f\"  Max: {bandwidth_per_second['bandwidth_mbps'].max():.2f} Mbps\")\n",
    "print(f\"  Std Dev: {bandwidth_per_second['bandwidth_mbps'].std():.2f} Mbps\")\n",
    "print(f\"\\nAverage frames per second: {bandwidth_per_second['frame_count'].mean():.1f} fps\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# 1. Bandwidth usage over time (in Mbps)\n",
    "axes[0].plot(bandwidth_per_second['time_offset'], bandwidth_per_second['bandwidth_mbps'], \n",
    "             marker='o', linewidth=2, markersize=4, color='steelblue', label='Bandwidth (Mbps)')\n",
    "axes[0].axhline(y=bandwidth_per_second['bandwidth_mbps'].mean(), color='red', \n",
    "                linestyle='--', linewidth=2, label=f'Average: {bandwidth_per_second[\"bandwidth_mbps\"].mean():.2f} Mbps')\n",
    "axes[0].set_xlabel('Time (seconds)', fontsize=14)\n",
    "axes[0].set_ylabel('Bandwidth (Mbps)', fontsize=14)\n",
    "axes[0].set_title('Video Transmission Bandwidth Over Time', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[0].set_xlim(bandwidth_per_second['time_offset'].min() - 0.5, bandwidth_per_second['time_offset'].max() + 0.5)\n",
    "axes[0].set_ylim(0, 10)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# 2. Frames per second over time\n",
    "axes[1].bar(bandwidth_per_second['time_offset'], bandwidth_per_second['frame_count'], \n",
    "            width=0.8, alpha=0.7, color='orange', edgecolor='darkorange')\n",
    "axes[1].axhline(y=bandwidth_per_second['frame_count'].mean(), color='purple', \n",
    "                linestyle='--', linewidth=2, label=f'Average: {bandwidth_per_second[\"frame_count\"].mean():.1f} fps')\n",
    "axes[1].set_xlabel('Time (seconds)', fontsize=14)\n",
    "axes[1].set_ylabel('Frames Received', fontsize=14)\n",
    "axes[1].set_xlim(bandwidth_per_second['time_offset'].min() - 0.5, bandwidth_per_second['time_offset'].max() + 0.5)\n",
    "axes[1].set_ylim(0, 65)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display first few rows of bandwidth data\n",
    "print(\"\\nFirst 10 seconds of bandwidth data:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f5abb",
   "metadata": {},
   "source": [
    "#### 4. Command Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file and parse each line as JSON\n",
    "command_data = []\n",
    "with open(file_command_latency, \"r\") as file:\n",
    "    for line in file:\n",
    "        command_data.append(json.loads(line.strip()))\n",
    "\n",
    "# Display the data\n",
    "print(f\"Total commands loaded: {len(command_data)}\")\n",
    "print(\"\\nFirst few commands:\")\n",
    "for i, cmd in enumerate(command_data[:5]):\n",
    "    print(f\"{i+1}. {cmd}\")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "command_df = pd.DataFrame(command_data)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(command_df)\n",
    "\n",
    "# export to csv\n",
    "command_df.to_csv(\"command_latency_analysis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2867305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Time series analysis of command latencies\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Calculate averages\n",
    "avg_latency = command_df['latency'].mean()\n",
    "avg_size = command_df['size'].mean()\n",
    "\n",
    "# 1. Data size over command sequence (top subplot)\n",
    "axes[0].bar(command_df['command_id'], command_df['size'], width=0.8, alpha=0.8, \n",
    "            color='orange', edgecolor='darkorange', linewidth=0.5, label='Command Data Size')\n",
    "\n",
    "# Add horizontal line for average data size\n",
    "axes[0].axhline(y=avg_size, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Average Data Size: {avg_size:.2f} bytes')\n",
    "\n",
    "axes[0].set_xlabel('Command ID', fontsize=14)\n",
    "axes[0].set_ylabel('Data Size (bytes)', fontsize=14)\n",
    "axes[0].set_ylim(0, 250)  # Set y-axis static limit for better visualization\n",
    "axes[0].set_title('Command Data Size Over Time', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Latency over command sequence (bottom subplot)\n",
    "axes[1].bar(command_df['command_id'], command_df['latency'], width=0.8, alpha=0.8, \n",
    "            color='steelblue', edgecolor='navy', linewidth=0.5, label='Command Latency')\n",
    "\n",
    "# Add horizontal line for average latency\n",
    "axes[1].axhline(y=avg_latency, color='purple', linestyle='--', linewidth=2,\n",
    "                label=f'Average Latency: {avg_latency:.2f} ms')\n",
    "\n",
    "axes[1].set_xlabel('Command ID', fontsize=14)\n",
    "axes[1].set_ylabel('Latency (ms)', fontsize=14)\n",
    "axes[1].set_ylim(0, 300)  # Set y-axis static limit for better visualization\n",
    "axes[1].set_title('Command Latency Over Time', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2867305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Analysis of missing commands\n",
    "if not command_df.empty:\n",
    "    # Find the first and last command IDs\n",
    "    first_command_id = command_df['command_id'].min()\n",
    "    last_command_id = command_df['command_id'].max()\n",
    "\n",
    "    # Calculate the total number of expected commands\n",
    "    total_expected_commands = last_command_id - first_command_id + 1\n",
    "\n",
    "    # Calculate the number of received commands\n",
    "    received_commands_count = len(command_df)\n",
    "\n",
    "    # Calculate the number of missing commands\n",
    "    missing_commands_count = total_expected_commands - received_commands_count\n",
    "\n",
    "    print(f\"First received command ID: {first_command_id}\")\n",
    "    print(f\"Last received command ID: {last_command_id}\")\n",
    "    print(f\"Total expected commands in sequence: {total_expected_commands}\")\n",
    "    print(f\"Number of received commands: {received_commands_count}\")\n",
    "    print(f\"Number of missing commands: {missing_commands_count}\")\n",
    "    print(f\"Missing command percentage: {(missing_commands_count/total_expected_commands)*100:.2f}%\")\n",
    "\n",
    "    # Identify the missing command IDs\n",
    "    expected_command_ids = set(range(first_command_id, last_command_id + 1))\n",
    "    received_command_ids = set(command_df['command_id'])\n",
    "    missing_command_ids = sorted(list(expected_command_ids - received_command_ids))\n",
    "\n",
    "    print(f\"\\nMissing command IDs: {missing_command_ids if missing_commands_count > 0 else 'None'}\")\n",
    "\n",
    "    # Create visualization - only upper part\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    # Overall view with improved markers\n",
    "    all_commands = pd.DataFrame({'command_id': list(range(first_command_id, last_command_id + 1))})\n",
    "    all_commands['status'] = 'Missing'\n",
    "    all_commands.loc[all_commands['command_id'].isin(received_command_ids), 'status'] = 'Received'\n",
    "\n",
    "    # Plot with larger, more visible markers\n",
    "    received_data = all_commands[all_commands['status'] == 'Received']\n",
    "    missing_data = all_commands[all_commands['status'] == 'Missing']\n",
    "\n",
    "    ax.scatter(received_data['command_id'], [1]*len(received_data),\n",
    "               c='green', alpha=0.6, s=50, marker='o', label=f'Received ({len(received_data)})')\n",
    "    ax.scatter(missing_data['command_id'], [1]*len(missing_data),\n",
    "               c='red', s=50, marker='x', label=f'Missing ({len(missing_data)})', linewidths=2)\n",
    "\n",
    "    ax.set_title('Visualization of Received and Missing Commands (Overall View)',\n",
    "                 fontsize=14, fontweight='bold', pad=25)\n",
    "    ax.set_xlabel('Command ID', fontsize=16)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend(title='Command Status', fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    if missing_command_ids:\n",
    "        print(f\"\\nMissing Command Analysis:\")\n",
    "        print(f\"- First missing command: {min(missing_command_ids)}\")\n",
    "        print(f\"- Last missing command: {max(missing_command_ids)}\")\n",
    "        print(f\"- Average gap between consecutive missing commands: {np.mean(np.diff(missing_command_ids)):.1f}\")\n",
    "        print(f\"- Largest gap between consecutive missing commands: {max(np.diff(missing_command_ids))}\")\n",
    "\n",
    "else:\n",
    "    print(\"Command data is empty. Cannot perform missing command analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268beeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.25 Box plot analysis of command latencies\n",
    "# Create box plot for all command latencies (combined)\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Create box plot\n",
    "box_plot = plt.boxplot([command_df['latency'].values],\n",
    "                        labels=['Command Latency'],\n",
    "                        patch_artist=True,\n",
    "                        showmeans=False,\n",
    "                        medianprops=dict(color='black', linewidth=2),\n",
    "                        boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                        whiskerprops=dict(linewidth=1.5),\n",
    "                        capprops=dict(linewidth=1.5))\n",
    "\n",
    "plt.ylabel('Latency (ms)', fontsize=14, fontweight='bold')\n",
    "plt.title('Command Latency Distribution (All Commands)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 300)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add statistics annotations\n",
    "stats_text = f\"n = {len(command_df)}\\n\"\n",
    "stats_text += f\"Mean = {command_df['latency'].mean():.2f} ms\\n\"\n",
    "stats_text += f\"Median = {command_df['latency'].median():.2f} ms\\n\"\n",
    "stats_text += f\"Std Dev = {command_df['latency'].std():.2f} ms\\n\"\n",
    "stats_text += f\"Min = {command_df['latency'].min():.2f} ms\\n\"\n",
    "stats_text += f\"Max = {command_df['latency'].max():.2f} ms\\n\"\n",
    "stats_text += f\"Q1 = {command_df['latency'].quantile(0.25):.2f} ms\\n\"\n",
    "stats_text += f\"Q3 = {command_df['latency'].quantile(0.75):.2f} ms\\n\"\n",
    "stats_text += f\"IQR = {command_df['latency'].quantile(0.75) - command_df['latency'].quantile(0.25):.2f} ms\"\n",
    "\n",
    "# Add text box with statistics\n",
    "plt.text(1.25, command_df['latency'].median(), stats_text,\n",
    "         fontsize=11, verticalalignment='center',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daefcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Box plot analysis of command latencies\n",
    "\n",
    "# Group commands by type and analyze latencies\n",
    "print(\"Command types and their counts:\")\n",
    "print(command_df['instruction'].value_counts())\n",
    "print(\"\\nLatency statistics by command type:\")\n",
    "print(command_df.groupby('instruction')['latency'].describe())\n",
    "\n",
    "# Create box plot for command latencies by type\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create box plot\n",
    "box_plot = plt.boxplot([command_df[command_df['instruction'] == cmd]['latency'].values \n",
    "                         for cmd in command_df['instruction'].unique()],\n",
    "                        labels=command_df['instruction'].unique(),\n",
    "                        patch_artist=True,\n",
    "                        showmeans=False,\n",
    "                        medianprops=dict(color='black', linewidth=2),\n",
    "                        boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                        whiskerprops=dict(linewidth=1.5),\n",
    "                        capprops=dict(linewidth=1.5))\n",
    "\n",
    "plt.xlabel('Command Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Latency (ms)', fontsize=14, fontweight='bold')\n",
    "plt.title('Command Latency Distribution by Command Type', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 300)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add sample size annotations\n",
    "for i, cmd in enumerate(command_df['instruction'].unique(), 1):\n",
    "    count = len(command_df[command_df['instruction'] == cmd])\n",
    "    median_val = command_df[command_df['instruction'] == cmd]['latency'].median()\n",
    "    plt.text(i, median_val, f'n={count}', \n",
    "             ha='center', va='bottom', fontsize=10, \n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics for each command type\n",
    "print(\"\\nDetailed statistics by command type:\")\n",
    "for cmd in command_df['instruction'].unique():\n",
    "    cmd_data = command_df[command_df['instruction'] == cmd]['latency']\n",
    "    print(f\"\\n{cmd}:\")\n",
    "    print(f\"  Count: {len(cmd_data)}\")\n",
    "    print(f\"  Mean: {cmd_data.mean():.2f} ms\")\n",
    "    print(f\"  Median: {cmd_data.median():.2f} ms\")\n",
    "    print(f\"  Std Dev: {cmd_data.std():.2f} ms\")\n",
    "    print(f\"  Min: {cmd_data.min():.2f} ms\")\n",
    "    print(f\"  Max: {cmd_data.max():.2f} ms\")\n",
    "    print(f\"  Q1 (25%): {cmd_data.quantile(0.25):.2f} ms\")\n",
    "    print(f\"  Q3 (75%): {cmd_data.quantile(0.75):.2f} ms\")\n",
    "    print(f\"  IQR: {cmd_data.quantile(0.75) - cmd_data.quantile(0.25):.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400c65e",
   "metadata": {},
   "source": [
    "#### 5. Hardware Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689aa44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# read the file and parse each line safely as Python dict literal\n",
    "hw_usage_data = []\n",
    "with open(hardware_usage, \"r\") as file:\n",
    "    for line in file:\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        try:\n",
    "            hw_usage_data.append(ast.literal_eval(s))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping malformed line: {e}\")\n",
    "            continue\n",
    "\n",
    "# Display the data\n",
    "print(f\"Total hardware usage records loaded: {len(hw_usage_data)}\")\n",
    "print(\"\\nFirst few hardware usage records:\")\n",
    "for i, record in enumerate(hw_usage_data[:5]):\n",
    "    print(f\"{i+1}. {record}\")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "hw_usage_df = pd.DataFrame(hw_usage_data)\n",
    "print(\"\\nDataFrame:\")\n",
    "print(hw_usage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Time series analysis of CPU/RAM/GPU usage (grouped bars)\n",
    "# Convert 'created_at' to datetime and aggregate per second using resample\n",
    "hw_usage_df['timestamp'] = pd.to_datetime(hw_usage_df['created_at'], unit='ms')\n",
    "per_second = (hw_usage_df.set_index('timestamp')\n",
    "               .resample('1s').agg({\n",
    "                   'cpu_usage_percent': 'mean',\n",
    "                   'ram_usage_percent': 'mean',\n",
    "                   'gpu_usage_percent': 'mean'\n",
    "               })\n",
    "               .reset_index()\n",
    "               .rename(columns={\n",
    "                   'cpu_usage_percent': 'cpu_usage_mean',\n",
    "                   'ram_usage_percent': 'ram_usage_mean',\n",
    "                   'gpu_usage_percent': 'gpu_usage_mean'\n",
    "               }))\n",
    "\n",
    "# Integer x-axis (seconds since start) for grouped bars\n",
    "per_second['time_offset'] = (per_second['timestamp'] - per_second['timestamp'].min()).dt.total_seconds().astype(int)\n",
    "x = np.arange(len(per_second))\n",
    "cpu = per_second['cpu_usage_mean'].values\n",
    "ram = per_second['ram_usage_mean'].values\n",
    "gpu = per_second['gpu_usage_mean'].values\n",
    "\n",
    "# Plot grouped bar chart\n",
    "plt.figure(figsize=(16, 6))\n",
    "bar_w = 0.25\n",
    "plt.bar(x - bar_w, cpu, width=bar_w, alpha=0.9, color='steelblue', edgecolor='navy', linewidth=0.4, label='CPU (%)')\n",
    "plt.bar(x, ram, width=bar_w, alpha=0.9, color='seagreen', edgecolor='darkgreen', linewidth=0.4, label='RAM (%)')\n",
    "plt.bar(x + bar_w, gpu, width=bar_w, alpha=0.9, color='coral', edgecolor='darkred', linewidth=0.4, label='GPU (%)')\n",
    "\n",
    "plt.title('Resource Usage per Second (Mean)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Time offset (s)', fontsize=12)\n",
    "plt.ylabel('Usage (%)', fontsize=12)\n",
    "plt.xlim(-0.5, len(x) - 0.5)\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.legend(fontsize=10, ncol=3, frameon=True)\n",
    "\n",
    "# Reduce x tick clutter\n",
    "if len(x) > 0:\n",
    "    max_idx = len(x) - 1\n",
    "    tick_positions = np.linspace(0, max_idx, num=min(12, len(x))).astype(int)\n",
    "    tick_labels = per_second.loc[tick_positions, 'time_offset'].astype(int).tolist()\n",
    "    plt.xticks(tick_positions, [str(t) for t in tick_labels])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print quick stats\n",
    "print(\"\\nPer-second mean usage stats:\")\n",
    "print(f\"  Seconds: {len(per_second)}\")\n",
    "print(f\"  CPU  -> mean {per_second['cpu_usage_mean'].mean():.2f}%, min {per_second['cpu_usage_mean'].min():.2f}%, max {per_second['cpu_usage_mean'].max():.2f}%\")\n",
    "print(f\"  RAM  -> mean {per_second['ram_usage_mean'].mean():.2f}%, min {per_second['ram_usage_mean'].min():.2f}%, max {per_second['ram_usage_mean'].max():.2f}%\")\n",
    "print(f\"  GPU  -> mean {per_second['gpu_usage_mean'].mean():.2f}%, min {per_second['gpu_usage_mean'].min():.2f}%, max {per_second['gpu_usage_mean'].max():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13026f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
